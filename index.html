<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>UM NLP Workshop</title>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-86897413-1', 'auto');
    ga('send', 'pageview');

    </script>

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
		<script src="js/bootstrap.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>
    <div class="container">

      <div class="page-header">
        <h1>UM NLP Workshop</h1>
        <p class="lead">December 2nd, 2016, 1pm - 8pm</p>
      </div>

      <h3>Location</h3>
      <ul>
        <li>Talks: GFL 107, <a href="https://goo.gl/maps/rtxPr2jCr9K2">[map]</a></li>
        <li>Dinner: BBB 3725</li>
      </ul>

      <h3>Workshop Chairs</h3>
      <p>If you have any questions, please contact us!</a>
      <ul>
        <li><a href="https://www.linkedin.com/in/meixing-dong-aa836a59">MeiXing Dong</a>, PhD student in CSE (meixingd)</li>
        <li><a href="http://www.jkk.name">Jonathan Kummerfeld</a>, Postdoc in CSE (jkummerf)</li>
      </ul>

      <h3>Talk preparation</h3>
      <p>
        Most attendees will give a talk on their current research.
        Faculty, Postdocs, and PhD students will give 10 minute talks.
        Masters and Undergraduate students will give 2 minute lightning talks.
        All talks will be timed, with an iPad displaying your time remaining.
      </p>
      <p>
        We will be using a single laptop on the day for all talks to avoid losing time between speakers.
        The computer will be a Macbook Pro with macOS 10.12, Keynote 7.0.5, and Microsoft Office 2016 for Mac.
        Please set the filename of your presentation to start with your name, e.g. Jane_Doe.key and provide us with BOTH the presentation file and a version that has been exported to PDF.
        We have prepared several talk templates:</p>
      <ul>
        <li><a href="https://drive.google.com/open?id=0Bxm7L4IzTm-WOC1nNWxhZ1ZZakk">Keynote</a></li>
        <li><a href="https://drive.google.com/open?id=0Bxm7L4IzTm-WaWM1M2IwcGlPVFk">Powerpoint</a> </li>
        <li><a href="https://docs.google.com/a/umich.edu/presentation/d/1XOttdRNNXBZ32_VhPN3nPYXIlmJNsCOrqN8IfTH65CU/edit?usp=sharing">Google Slides</a></li>
      </ul>

      <h4>Lightning talk specific guidelines</h4>
      <p>
        All lightning talks will be presented as PDFs and contain a title slide and either 1 or 2 content slides.
      </p>
      <p>
        This will allow us to combine them all into one long presentation, saving time on the day.
        The advantage of PDF is that you can use any slide creation program you want, but the downside is that you cannot have complex animation.
        We recommend the three slides be: a title slide, a project description slide, and a results slide.
        If simple animations cause these three slides to become more than three when exported to PDF that's fine.
      </p>

      <h3>Program</h3>



<table class="table">
  <thead>
    <tr>
      <th>Start Time</th>
      <th>Event</th>
      <th>Speaker</th>
      <th>Title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>13:10</td>
      <td>Welcome</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
    </tr>
    <tr>
      <td>13:20</td>
      <td>Faculty talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Dragomir Radev
Rada Mihalcea
Steve Abney</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"><a href="#mycollapse0" data-toggle="collapse">NLP Projects in CLAIR</a><div style="max-width:400px" id="mycollapse0" class="collapse">
I will briefly introduce some of the current research projects in the CLAIR (Computational Linguistics And Information Retrieval) lab such as NLP for collective discourse, graph-based NLP, signed network analysis, sentence similarity clustering, NLP for scientometrics, and dialogue systems for student advising. I will also talk about some current educational activities such as the NACLO competition, the Intro to NLP Coursera MOOC, and the All About NLP web site.</div>

</td>
    </tr>
    <tr>
      <td>13:55</td>
      <td>PhD talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Shibamouli Lahiri
MeiXing Dong
Aparna Garimella
Catherine Finegan-Dollak
Laura Wendlandt</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">


<a href="#mycollapse1" data-toggle="collapse">Seq2Seq Semantic Parsing for Natural Language to SQL</a><div style="max-width:400px" id="mycollapse1" class="collapse">
A dialog system for student advising can store helpful information in a relational database. How should we translate English questions into SQL queries to access that information? We propose building upon a sequence to sequence semantic parser by adding attention over the database schema.</div>
</td>
    </tr>
    <tr class="success">
      <td>14:50</td>
      <td>Tea Break</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
    </tr>
    <tr>
      <td>15:20</td>
      <td>Faculty talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Berrin Yanikoglu
Vinod Vydiswaran</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">
</td>
    </tr>
    <tr>
      <td>15:45</td>
      <td>Postdoctoral talk</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Veronica Perez-Rosas</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
    </tr>
    <tr>
      <td>16:00</td>
      <td>PhD talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Charles Welch
Luke Brandl
Qiaozhu Mei / Cheng Li</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">

<a href="#mycollapse2" data-toggle="collapse">Deep Memory Networks for Attitude Identification</a><div style="max-width:400px" id="mycollapse2" class="collapse">
We consider the task of identifying attitude towards a given set of entities from text. Conventionally, this task is decomposed into two separate subtasks: target detection that identifies whether each entity is mentioned either explicitly or implicitly in the text, and polarity classification that classifies the exact sentiment towards an identified entity (the target) into either positive, negative, or neutral.

Instead, we show that attitude identification can be solved with an end-to-end machine learning architecture, with the two subtasks interleaved by a deep memory network. In this way, signals produced in target detection provide clues to polarity classification, and reversely, polarity provides feedback to the first subtask. Moreover, the treatments of the set of targets also influence each other -- the learned representations may share the same semantics for many targets but vary for some targets. The proposed deep memory network outperforms models that do not consider the interactions between the subtasks or among the targets, including conventional methods and the state-of-the-art deep learning models. </div></td>
    </tr>
    <tr>
      <td>16:35</td>
      <td>Undergraduate talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">John Moon
Marissa Inga
Joseph Peper
Sesh Sadasivam
Thomas Searle
Yulin Xie
Harry Zhang
Noriyuki Kojima</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">




-
ACL Anthology Network (AAN)
-</td>
    </tr>
    <tr class="warning">
      <td>16:55</td>
      <td>Group Photo</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
    </tr>
    <tr class="success">
      <td>17:00</td>
      <td>Tea Break</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
    </tr>
    <tr>
      <td>17:30</td>
      <td>Postdoctoral talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Jonathan Kummerfeld
Tanmay Basu
Mohamed Abouelenien</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">
<a href="#mycollapse3" data-toggle="collapse">Identifying Severity in Neuropsychiatric Clinical Notes</a><div style="max-width:400px" id="mycollapse3" class="collapse">
In this work, we studied the problem of classifying symptom severity from neuropsychiatric clinical records using supervised machine learning approaches. The data is released as part of the Neuropsychiatric Genome-Scale NLP challenge 2016 organized by i2b2 (Informatics for Integrating Biology and the Bedside), a NIH-funded national center at Partners Health Care System. The participants of the shared task are provided with the raw clinical notes from the initial psychiatric evaluation of patients. The patient records in the training data are categorized into four classes, viz., absent, mild, moderate, and severe. As part of our investigation, we explored features derived from the template-based text in the clinical notes, a medical thesauri such as UMLS, and corpus-based weighting in the training set. A Random Forest classifier is trained on this feature sets to classify the test samples. The experimental results suggest that the proposed framework achieves high accuracy.</div>
</td>
    </tr>
    <tr>
      <td>18:05</td>
      <td>PhD talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Mahmoud Azab
Nikita Bhutani
Steven Wilson
Rui Zhang</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">
<a href="#mycollapse4" data-toggle="collapse">Domain-independent framework for extracting, representing and querying knowledge from text</a><div style="max-width:400px" id="mycollapse4" class="collapse">
Traditional information retrieval and query mechanisms are insufficient to meet todayâ€™s complex information needs and unlock the value in the unprecedented volume of text data on the web today. We need semantic technologies capable of identifying and organizing knowledge encoded in the text to support these complex needs. We need to develop structured representations that go beyond current efforts to curate knowledge about entities and relations. We also need effective and expressive query mechanisms that provide declarative access to this knowledge.</div>

<a href="#mycollapse5" data-toggle="collapse">Interleaving Speaker Thoughts via RNNs in Multi-Turn Dialogs</a><div style="max-width:400px" id="mycollapse5" class="collapse">
We focus on the task of response selection for the retrieval-based conversation agents by modeling unstructured, multi-turn, two-party dialogs.  Current response selection approaches are limited to small contexts and view the multi-turn context as a long sequence of words.  Motivated by this observation, we propose Interleaving-Thoughts Recurrent Neural Network (IT-RNN).  Our model constructs representations for individual utterances via low-level networks, and then high-level layers produces intrinsic dynamics of conversations via intention flows and information exchanges.  This enables neural networks to deal with arbitrary lengths of conversation history and catch discourse information and utterance dependency among two speakers.  We build IT-RNN on top of vanilla RNN, GRU, and LSTM units.  We evaluate our model on two public available multi-turn dialog corpora.  Experimental results show that our system significantly outperforms traditional Information Retrieval methods and other neural network baselines.</div></td>
    </tr>
    <tr>
      <td>18:50</td>
      <td>Masters talks</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">Karthik Ramanathan
Yi Wan
Xinyan Zhao</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;">

<a href="#mycollapse6" data-toggle="collapse">Hybrid Clinical Named Entity Recognition System</a><div style="max-width:400px" id="mycollapse6" class="collapse">
We are developing a clinical hybrid NER system that identifies Protected Health Information(PHI) with four components: preprocessing component, regular expression component, CRF component, and a combiner.</div></td>
    </tr>
    <tr class="success">
      <td>19:00</td>
      <td>Dinner</td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
      <td style="white-space:pre-wrap ; word-wrap:break-word;"></td>
    </tr>
  </tbody>
</table>


    </div> <!-- /container -->

    <!-- Enable tooltips -->
    <script>
    $(document).ready(function(){
          $('[data-toggle="tooltip"]').tooltip();   
    });
    </script>
  </body>
</html>
